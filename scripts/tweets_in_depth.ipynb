{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tweets\n",
    "\n",
    "This notebook is for cleaning the tweets and tokenizing with a subsequent analysis.\n",
    "\n",
    "\n",
    "Actually, these guys: https://link.springer.com/chapter/10.1007/978-3-319-09339-0_62 argue that lemmatization and stemming lead to worse performance in terms of sentiment analysis, while features reservation, negation transformation and repeated letters normalization improves it. They also get better results when by using bigrams and emotions features.\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S1877050913001385\n",
    "\n",
    "Also: Stop Word removal might not be necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/adam/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import swifter\n",
    "import pickle\n",
    "\n",
    "# Text mining packages\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "# Import cleaning function\n",
    "from utils.cleaning import clean_tweet, has_arabic, has_cyrillic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading tweets and user data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already cleaned the tweets a bit checking for user locations and so on. Now it's time to clean the texts, tokenize, remove stop words and so on.\n",
    "\n",
    "```clean_tweet``` does a bunch of stuff, including removal of retweets, hyperlinks, emojis and so on.\n",
    "\n",
    "We're removing retweets because we're interested in the \"content-creators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccec7a9dd509445eb7ff360d2e3a5347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=2536417, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_pickle(\"../data/tweets_clean.pickle\")\n",
    "users = pd.read_pickle(\"../data/user_clean.pickle\")\n",
    "\n",
    "# Clean\n",
    "tweets[\"tweet_text\"] = tweets[\"tweet_text\"].swifter.apply(clean_tweet)\n",
    "\n",
    "# Save it, just to make sure nothing gets lost\n",
    "with open('../data/tweets_preprocessed.pickle', 'wb') as f:\n",
    "    pickle.dump(tweets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning, we can tokenize. Hashtags should be helpful with getting meaningful embeddings since they contain information about the topic. We could later check whether there are differences in embeddings / clusters with or without hashtags. We also remove stopwords using nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Set stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Tokenize\n",
    "tweets_tokenized = [tokenizer.tokenize(t) for t in tweets[\"tweet_text\"]]\n",
    "\n",
    "# Remove stopwords\n",
    "tweets_tokenized_noSwords = [[w for w in tweet_tokens if w not in stop_words] for tweet_tokens in tweets_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tweets_tokenized.pickle', 'wb') as f:\n",
    "    pickle.dump(tweets_tokenized_noSwords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
